{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание 1, теоретическая часть.**\n",
    "\n",
    "**Луничкин Егор, 396 гр.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контрольные вопросы (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Что является объектом в задаче обучения ранжированию? Какой смысл имеют целевые метки? Какие объекты сравнимы между собой?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объектом в задаче ранжирования является пара $(q, d)$, где $q~-$ запрос, а $d~-$ документ, то есть мы хотим для каждого запроса возвращать наиболее \"релевантный\" для него документ.\n",
    "\n",
    "Целевая метка$~-$ это, соответственно, мера \"релевантности\" документа $d$ запросу $q$. Сравнимы между собой только документы в рамках одного и того же запроса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** В чём преимущество метрики NDCG перед метрикой MAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В метрике NDCG в отличие от метрики MAP функции оценки релевантности могут быть вещественными, то есть мы можем оценить степень релевантности документа $d$ запросу $q$, а не просто понять бинарный факт: релевантен запрос или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Опишите причину неустойчивости PLSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с отсутствием ограничений по регуляризации PLSA подвержена переполнению из-за большого количества параметров $\\phi_{wd}$ и $\\theta_{td}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** На каких выборках наиболее заметна разница в работе PLSA и LDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выборках, в которых число тем у каждого из документов мало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** По каким причинам в ЕМ-алгоритме для тематического моделирования E-шаг встраивается внутрь М-шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица $H_{dwt}$ распределения между документами $d$, словами $w$ и темами $t$ вычисляется не целиком, а частично, по мере прохода по набору документов $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Опишите применение тематического моделирования в задаче информационного поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование в задаче информационного поиска можно применять, например, для нахождения документов по заданным темам, анализа тематической структуры документа, выделения основных тем документа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** В чем основная причина сложности обработки русского языка по сравнению с английским?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Отсутствие строгого порядка слов в предложениях.\n",
    "* Наличие различных форм у одного и того же слова (окончания в разных падежах, спряжение глаголов).\n",
    "* У различных форм одного слова могут быть различные признаки и свойства, поэтому возникают сложности при построении векторного представления слова (одно представление на слово или разные для каждой формы?).\n",
    "* Наличие омонимов, в том числе представляющих различные части речи, например \"село\" (сущ.) и \"село\" (гл.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)** Каким образом парсинг зависимостей между словами помогает в решении задач обработки естественного языка?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выделение ключевых слов и темы предложения.\n",
    "* Разрешение кореференций, то есть сопоставление местоимению существительного, которое оно заменяет.\n",
    "* Извлечение синтаксических конструкций из текста, что зачастую позволяет разрешить омонимию (пример в 7 вопросе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)** Что такое кореференции?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кореференция$~-$ связывание нескольких отсылок в документе к одному реальному объекту, например: замена существительного на местоимение, использование синонимов, аббревиатур."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** В чем отличие между CBOW и Skip-gram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Суть работы CBOW$~-$ обучение нейронной сети для предсказания слова по его контексту, то есть $p(v|w) = \\frac{\\exp(B_v^T(\\sum_{j}A_j))}{\\sum_s\\exp(B_s^T(\\sum_{j}A_j)))}$.\n",
    "* Суть работы Skip-gram$~-$ наоборот, обучение нейронной сети для предсказания контекста по данному слову, то есть $p(v|w) = \\frac{\\exp(B_v^T A_w)}{\\sum_s\\exp(B_s^T A_w)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте PageRank для заданного графа вручную и при помощи алгоритма, описанного в семинаре. Результаты сравните."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
