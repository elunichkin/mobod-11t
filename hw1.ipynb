{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание 1, теоретическая часть.**\n",
    "\n",
    "**Луничкин Егор, 396 гр.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контрольные вопросы (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Что является объектом в задаче обучения ранжированию? Какой смысл имеют целевые метки? Какие объекты сравнимы между собой?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объектом в задаче ранжирования является пара $(q, d)$, где $q~-$ запрос, а $d~-$ документ, то есть мы хотим для каждого запроса возвращать наиболее \"релевантный\" для него документ.\n",
    "\n",
    "Целевая метка$~-$ это, соответственно, мера \"релевантности\" документа $d$ запросу $q$. Сравнимы между собой только документы в рамках одного и того же запроса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** В чём преимущество метрики NDCG перед метрикой MAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В метрике NDCG в отличие от метрики MAP функции оценки релевантности могут быть вещественными, то есть мы можем оценить степень релевантности документа $d$ запросу $q$, а не просто понять бинарный факт: релевантен запрос или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Опишите причину неустойчивости PLSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с отсутствием ограничений по регуляризации PLSA подвержена переполнению из-за большого количества параметров $\\phi_{wd}$ и $\\theta_{td}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** На каких выборках наиболее заметна разница в работе PLSA и LDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выборках, в которых число тем у каждого из документов мало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** По каким причинам в ЕМ-алгоритме для тематического моделирования E-шаг встраивается внутрь М-шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица $H_{dwt}$ распределения между документами $d$, словами $w$ и темами $t$ вычисляется не целиком, а частично, по мере прохода по набору документов $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Опишите применение тематического моделирования в задаче информационного поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование в задаче информационного поиска можно применять, например, для нахождения документов по заданным темам, анализа тематической структуры документа, выделения основных тем документа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** В чем основная причина сложности обработки русского языка по сравнению с английским?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Отсутствие строгого порядка слов в предложениях.\n",
    "* Наличие различных форм у одного и того же слова (окончания в разных падежах, спряжение глаголов).\n",
    "* У различных форм одного слова могут быть различные признаки и свойства, поэтому возникают сложности при построении векторного представления слова (одно представление на слово или разные для каждой формы?).\n",
    "* Наличие омонимов, в том числе представляющих различные части речи, например \"село\" (сущ.) и \"село\" (гл.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)** Каким образом парсинг зависимостей между словами помогает в решении задач обработки естественного языка?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выделение ключевых слов и темы предложения.\n",
    "* Разрешение кореференций, то есть сопоставление местоимению существительного, которое оно заменяет.\n",
    "* Извлечение синтаксических конструкций из текста, что зачастую позволяет разрешить омонимию (пример в 7 вопросе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)** Что такое кореференции?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кореференция$~-$ связывание нескольких отсылок в документе к одному реальному объекту, например: замена существительного на местоимение, использование синонимов, аббревиатур."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** В чем отличие между CBOW и Skip-gram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Суть работы CBOW$~-$ обучение нейронной сети для предсказания слова по его контексту, то есть $p(v|w) = \\frac{\\exp(B_v^T(\\sum_{j}A_j))}{\\sum_s\\exp(B_s^T(\\sum_{j}A_j)))}$.\n",
    "* Суть работы Skip-gram$~-$ наоборот, обучение нейронной сети для предсказания контекста по данному слову, то есть $p(v|w) = \\frac{\\exp(B_v^T A_w)}{\\sum_s\\exp(B_s^T A_w)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посчитайте PageRank для заданного графа вручную и при помощи алгоритма, описанного в семинаре. Результаты сравните."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To be continued*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пользователь браузера в дополнение к кликам по ссылкам один раз может перейти по кнопке *Назад* и вернуться на предыдущую страницу. Можно ли такую модель описать с помощью однородной марковской цепи? Если да, опишите, если нет, докажите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цепь Маркова называется **однородной**, если матрица переходных вероятностей не зависит от номера шага, то есть:\n",
    "\n",
    "$P_{ij}(n) = P_{ij}, \\forall{n} \\in N$\n",
    "\n",
    "Будем хранить в качестве состояния пару $(p_{cur}, p_{last}), то есть текущую страницу и предыдущую страницу (если предыдущей нет, то $-1$).\n",
    "\n",
    "Тогда добавим следующие переходы:\n",
    "* Если $\\exists$ ссылка из $p_1$ в $p_2$: $(*, p_1) \\rightarrow (p_1, p_2)$.\n",
    "* Для перехода назад: $(p_1, p_2) \\rightarrow (-1, p_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3 (15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Опишите вероятностные предположения, на которые опирается TF-IDF при подсчете вероятностей.\n",
    "\n",
    "#### Пусть задана колекция текстовых документов $d_1, d_2,\\ldots, d_n$, состоящая из двух видов слов: $w_1$ и $w_2$. В документе $d_i$ ровно $k_{i1}$ слов $w_1$ и $k_{i2}$ слов $w_2$.\n",
    "\n",
    "#### Оцените вероятность втретить $k$ раз слово $w_1$. Сравните с оценкой вероятности, используемой в TF-IDF.\n",
    "\n",
    "#### Совпадают ли эти значения? Если нет, проведите анализ \"источника\" различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To be continued*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задано 10 документов. Их отранжировали идеально, а затем 4 и 6 документы поменяли местами. Подсчитайте коэффициент ранговой корреляции ($\\tau$ Кенделла)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По определению:\n",
    "\n",
    "$\\tau = \\dfrac{P-Q}{C_n^2}$, где:\n",
    "\n",
    "* $P~-$ количество пар с совпадающим взаимным порядком,\n",
    "* $Q~-$ количество пар с несовпадающим взаимным порядком,\n",
    "* $n~-$ количество документов.\n",
    "\n",
    "Получим:\n",
    "\n",
    "$\\tau = \\dfrac{42-3}{45} = 0.8(6) \\approx 0.8667$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 6, 5, 4, 7, 8, 9, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "old = list(range(1, 11))\n",
    "new = old.copy()\n",
    "new[3], new[5] = new[5], new[3]\n",
    "\n",
    "print(old, new, sep='\\n')\n",
    "\n",
    "kendalltau(old, new).correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 5 (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С какой целью общеупотребительные слова исключают из рассмотрения при построении тематической модели? Если их не исключать, как это отразится на матрицах $\\Phi$ и $\\Theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Общеупотребительные слова (стоп-слова) содержатся в большинстве тем в большом количестве и не несут смысловой нагрузки: не позволяют определить ту или иную тему документа.\n",
    "* Для матрицы $\\Phi$. Из-за того, что вероятность встретить стоп-слово в любом тексте с любой темой большая, в строках матрицы будут записаны большие числа. В строках, соответствующих другим словам, будут находится сравнительно маленькие числа, снижая таким образом релевантность тематического поиска.\n",
    "* Для матрицы $\\Theta$. По определению $\\theta_{td} = p(t|d)$. При добавлении в рассмотрение общеупотребительных слов ко всем значениям $\\theta_{td}$ добавится константа. Таким образом, при дальнейшей нормировке уменьшится разброс чисел и, соответственно, дисперсия. Это ведёт к неустойчивости $EM$-алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
