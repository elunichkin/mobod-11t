{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание 1, теоретическая часть.**\n",
    "\n",
    "**Луничкин Егор, 396 гр.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контрольные вопросы (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Что является объектом в задаче обучения ранжированию? Какой смысл имеют целевые метки? Какие объекты сравнимы между собой?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объектом в задаче ранжирования является пара $(q, d)$, где $q~-$ запрос, а $d~-$ документ, то есть мы хотим для каждого запроса возвращать наиболее \"релевантный\" для него документ.\n",
    "\n",
    "Целевая метка$~-$ это, соответственно, мера \"релевантности\" документа $d$ запросу $q$. Сравнимы между собой только документы в рамках одного и того же запроса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** В чём преимущество метрики NDCG перед метрикой MAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В метрике NDCG в отличие от метрики MAP функции оценки релевантности могут быть вещественными, то есть мы можем оценить степень релевантности документа $d$ запросу $q$, а не просто понять бинарный факт: релевантен запрос или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Опишите причину неустойчивости PLSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с отсутствием ограничений по регуляризации PLSA подвержена переполнению из-за большого количества параметров $\\phi_{wd}$ и $\\theta_{td}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** На каких выборках наиболее заметна разница в работе PLSA и LDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выборках, в которых число тем у каждого из документов мало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** По каким причинам в ЕМ-алгоритме для тематического моделирования E-шаг встраивается внутрь М-шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица $H_{dwt}$ распределения между документами $d$, словами $w$ и темами $t$ вычисляется не целиком, а частично, по мере прохода по набору документов $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Опишите применение тематического моделирования в задаче информационного поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование в задаче информационного поиска можно применять, например, для нахождения документов по заданным темам, анализа тематической структуры документа, выделения основных тем документа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** В чем основная причина сложности обработки русского языка по сравнению с английским?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Отсутствие строгого порядка слов в предложениях.\n",
    "* Наличие различных форм у одного и того же слова (окончания в разных падежах, спряжение глаголов).\n",
    "* У различных форм одного слова могут быть различные признаки и свойства, поэтому возникают сложности при построении векторного представления слова (одно представление на слово или разные для каждой формы?).\n",
    "* Наличие омонимов, в том числе представляющих различные части речи, например \"село\" (сущ.) и \"село\" (гл.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)** Каким образом парсинг зависимостей между словами помогает в решении задач обработки естественного языка?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выделение ключевых слов и темы предложения.\n",
    "* Разрешение кореференций, то есть сопоставление местоимению существительного, которое оно заменяет.\n",
    "* Извлечение синтаксических конструкций из текста, что зачастую позволяет разрешить омонимию (пример в 7 вопросе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)** Что такое кореференции?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кореференция$~-$ связывание нескольких отсылок в документе к одному реальному объекту, например: замена существительного на местоимение, использование синонимов, аббревиатур."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** В чем отличие между CBOW и Skip-gram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Суть работы CBOW$~-$ обучение нейронной сети для предсказания слова по его контексту, то есть $p(v|w) = \\frac{\\exp(B_v^T(\\sum_{j}A_j))}{\\sum_s\\exp(B_s^T(\\sum_{j}A_j)))}$.\n",
    "* Суть работы Skip-gram$~-$ наоборот, обучение нейронной сети для предсказания контекста по данному слову, то есть $p(v|w) = \\frac{\\exp(B_v^T A_w)}{\\sum_s\\exp(B_s^T A_w)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посчитайте PageRank для заданного графа вручную и при помощи алгоритма, описанного в семинаре. Результаты сравните."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала пронумеруем вершины: центральную назовём $v_0$, остальные — $v_1 \\dots v_9$.\n",
    "\n",
    "Очевидно, что PageRank вершин $v_1 \\dots v_9$ будет совпадать. Обозначим его $p$, а PageRank вершины $v_0$ — $p_0$.\n",
    "\n",
    "Посчитаем по формуле $p(d) = \\dfrac{1-\\delta}{N} + \\delta\\sum_{c \\in D^{in}_{d}}\\dfrac{PR(c)}{|D^{out}_{c}|}$:\n",
    "\n",
    "$p_0 = \\dfrac{1-0.85}{9} + 0.85*8*\\dfrac{p}{3}$\n",
    "\n",
    "$p = \\dfrac{1-0.85}{9} + 0.85*2*\\dfrac{p}{3}$\n",
    "\n",
    "Решив систему и отнормировав, получим: $p_0 \\approx 0.252337, p \\approx 0.093458$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритм с семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25233404, 0.09227719, 0.09440902, 0.09279838, 0.09444309,\n",
       "       0.09266218, 0.09448459, 0.09214099, 0.09445052])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "adj = [[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "       [1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "       [1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
    "       [1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "       [1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
    "       [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    "       [1, 1, 0, 0, 0, 0, 0, 1, 0]]\n",
    "adj = np.array(adj)\n",
    "\n",
    "adj_norm = np.empty((adj.shape[0], adj.shape[0]))\n",
    "\n",
    "for j in range(len(adj)):\n",
    "    adj_norm[:,j] = adj[:,j] / adj[:,j].sum()\n",
    "\n",
    "def pagerank(G, d=0.85, e=1e-4):\n",
    "    n = G.shape[0]\n",
    "    v = np.random.rand(n)\n",
    "    v /= v.sum()\n",
    "    v_last = np.array([1. for _ in range(n)])\n",
    "    M = d*G + (1-d)/n * np.array([[1. for _ in range(n)] for _ in range(n)])\n",
    "    while np.square(v - v_last).sum() > e:\n",
    "        v_last = v\n",
    "        v = M.dot(v)\n",
    "    return v\n",
    "    \n",
    "pagerank(adj_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим результат с помощью NetworkX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.25233621974128034,\n",
       " 1: 0.09345797253233992,\n",
       " 2: 0.09345797253233992,\n",
       " 3: 0.09345797253233992,\n",
       " 4: 0.09345797253233992,\n",
       " 5: 0.09345797253233992,\n",
       " 6: 0.09345797253233992,\n",
       " 7: 0.09345797253233992,\n",
       " 8: 0.09345797253233992}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx.graph = nx.from_numpy_matrix(adj)\n",
    "nx.pagerank(nx.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пользователь браузера в дополнение к кликам по ссылкам один раз может перейти по кнопке *Назад* и вернуться на предыдущую страницу. Можно ли такую модель описать с помощью однородной марковской цепи? Если да, опишите, если нет, докажите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цепь Маркова называется **однородной**, если матрица переходных вероятностей не зависит от номера шага, то есть:\n",
    "\n",
    "$P_{ij}(n) = P_{ij}, \\forall{n} \\in N$\n",
    "\n",
    "Будем хранить в качестве состояния пару $(p_{cur}, p_{last})$, то есть текущую страницу и предыдущую страницу (если предыдущей нет, то $-1$).\n",
    "\n",
    "Тогда добавим следующие переходы:\n",
    "* Если $\\exists$ ссылка из $p_1$ в $p_2$: $(*, p_1) \\rightarrow (p_1, p_2)$.\n",
    "* Для перехода назад: $(p_1, p_2) \\rightarrow (-1, p_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3 (15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Опишите вероятностные предположения, на которые опирается TF-IDF при подсчете вероятностей.\n",
    "\n",
    "#### Пусть задана колекция текстовых документов $d_1, d_2,\\ldots, d_n$, состоящая из двух видов слов: $w_1$ и $w_2$. В документе $d_i$ ровно $k_{i1}$ слов $w_1$ и $k_{i2}$ слов $w_2$.\n",
    "\n",
    "#### Оцените вероятность встретить $k$ раз слово $w_1$. Сравните с оценкой вероятности, используемой в TF-IDF.\n",
    "\n",
    "#### Совпадают ли эти значения? Если нет, проведите анализ \"источника\" различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим опреления:\n",
    "* TF-IDF$(q,d)~-$ мера релевантности документа $d$ запросу $q$.\n",
    "* $n_{dw}~-$ число вхождений слова $w$ в документ $d$.\n",
    "* $N_w~-$ число документов, содержащих слово $w$.\n",
    "* $N~-$ общее число документов.\n",
    "* $\\dfrac{N_w}{N}~-$ вероятность встретить слово $w$ в случайном документе из набора.\n",
    "* $\\left(\\dfrac{N_w}{N}\\right)^{n_{dw}}~-$ вероятность встретить слово $w$ $n_{dw}$ раз.\n",
    "* $P(q, d) = \\prod_{w \\in q}{\\left(\\dfrac{N_w}{N}\\right)^{n_{dw}}}~-$ вероятность встретить в документе $d$ слова $w \\in q$ из запроса $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычная вероятность встретить $k$ раз слово $w_1$ равна $\\frac{\\sum_i{I(k_{i1}>=k)}}{n}$.\n",
    "Вероятность в случае TF-IDF равна $\\left(\\frac{\\sum_i{I(k_{i1}>0)}}{n}\\right)^{k}$.\n",
    "\n",
    "Числа будут совпадать, если количество документов, содержащих $k$ раз слово $w_1$ будет убывать экспоненциально быстро с ростом $k$.\n",
    "\n",
    "Если мы не накладываем никаких дополнительных ограничений, то эти вероятности будут отличаться (чем больше $k$, тем больше будет разница). Вероятности совпадаюи при $k=1$.\n",
    "\n",
    "Как мы выяснили, оценка TF-IDF будет экспоненциально быстро убывать с ростом $k$, в то время как \"обычная\" вероятность так быстро убывать не будет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задано 10 документов. Их отранжировали идеально, а затем 4 и 6 документы поменяли местами. Подсчитайте коэффициент ранговой корреляции ($\\tau$ Кенделла)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По определению:\n",
    "\n",
    "$\\tau = \\dfrac{P-Q}{C_n^2}$, где:\n",
    "\n",
    "* $P~-$ количество пар с совпадающим взаимным порядком,\n",
    "* $Q~-$ количество пар с несовпадающим взаимным порядком,\n",
    "* $n~-$ количество документов.\n",
    "\n",
    "Получим:\n",
    "\n",
    "$\\tau = \\dfrac{42-3}{45} = 0.8(6) \\approx 0.8667$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 6, 5, 4, 7, 8, 9, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "old = list(range(1, 11))\n",
    "new = old.copy()\n",
    "new[3], new[5] = new[5], new[3]\n",
    "\n",
    "print(old, new, sep='\\n')\n",
    "\n",
    "kendalltau(old, new).correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 5 (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С какой целью общеупотребительные слова исключают из рассмотрения при построении тематической модели? Если их не исключать, как это отразится на матрицах $\\Phi$ и $\\Theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Общеупотребительные слова (стоп-слова) содержатся в большинстве тем в большом количестве и не несут смысловой нагрузки: не позволяют определить ту или иную тему документа.\n",
    "* Для матрицы $\\Phi$. Из-за того, что вероятность встретить стоп-слово в любом тексте с любой темой большая, в строках матрицы будут записаны большие числа. В строках, соответствующих другим словам, будут находится сравнительно маленькие числа, снижая таким образом релевантность тематического поиска.\n",
    "* Для матрицы $\\Theta$. По определению $\\theta_{td} = p(t|d)$. При добавлении в рассмотрение общеупотребительных слов ко всем значениям $\\theta_{td}$ добавится константа. Таким образом, при дальнейшей нормировке уменьшится разброс чисел и, соответственно, дисперсия. Это ведёт к неустойчивости $EM$-алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 6 (25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задано значение $KL(P||Q)$. Можно ли оценить значение $KL(Q||P)$? Если да, то оцените; если нет, то обоснуйте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если $P$ и $Q$ имеют одинаковые распределения, то $KL(P||Q) = KL(Q||P) = 0$.\n",
    "\n",
    "В противном случае рассмотрим $P: p(0) = p(1) = \\dfrac12$, $Q: q(0) = \\dfrac1n, q(1) = \\dfrac{n-1}{n}$.\n",
    "\n",
    "Тогда $|KL(P||Q) - KL(Q||P)| = \\left|\\dfrac{1}{2}\\log\\left(\\dfrac{\\frac{1}{2}}{\\frac{n-1}{n}}\\right) + \\dfrac{1}{2}\\log\\left(\\dfrac{\\frac{1}{2}}{\\frac{1}{n}}\\right) - \\dfrac{n-1}{n}\\log\\left(\\dfrac{\\frac{n-1}{n}}{\\frac{1}{2}}\\right) + \\left(\\dfrac{1}{n}\\right)\\log\\left(\\dfrac{\\frac{1}{n}}{\\frac{1}{2}}\\right)\\right| \\ = \\ = \\left(\\dfrac{n+2}{2n}\\log\\left(\\dfrac{n-1}{2}\\right) + \\dfrac{3n-2}{2n}\\log\\left(\\dfrac{n-1}{2n}\\right)\\right) \\to \\infty, n \\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что разность между этими величинами, может как равняться $0$, так и стремиться к бесконечности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 7 (бонусная +25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим пример из семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">But \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is starting from behind. The company made a late push\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "into hardware, and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s Siri, available on \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Alexa\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "software, which runs on its \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Echo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Dot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " devices, have clear leads in\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "consumer adoption.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "text = \"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\"\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу заметно, что некорректные метки географических объектов расположены в местах перевода строки. Попробуем заменить их на пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">But \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is starting from behind. The company made a late push into hardware, and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s Siri, available on \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Alexa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " software, which runs on its \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Echo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Dot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " devices, have clear leads in consumer adoption.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text = text.replace('\\n', ' ')\n",
    "new_doc = nlp(new_text)\n",
    "displacy.render(new_doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, некорректные геометки пропали."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
